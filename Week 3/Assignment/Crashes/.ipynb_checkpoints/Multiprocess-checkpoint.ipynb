{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created Tuples\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from multiprocessing import Pool\n",
    "import multiprocessing\n",
    "import multiprocess as mp\n",
    "import worker\n",
    "\n",
    "import sqlite3\n",
    "\n",
    "import json, requests, os, urllib\n",
    "\n",
    "# Read sqlite query results into a pandas DataFrame\n",
    "con = sqlite3.connect(\"data/switrs.sqlite\")\n",
    "q = \"\"\"\n",
    "SELECT collision_date, longitude, latitude FROM collisions\n",
    "WHERE collision_date IS NOT NULL\n",
    "AND longitude IS NOT NULL\n",
    "AND latitude IS NOT NULL    \n",
    "AND collision_date <= '2017-12-31'  -- 2018 is incomplete\n",
    "AND collision_date >= '2017-01-01'\n",
    "\"\"\"\n",
    "df = pd.read_sql_query(q, con)\n",
    "df.latitude = round(df.latitude*2)/2\n",
    "df.longitude = round(df.longitude*2)/2\n",
    "df.drop_duplicates(inplace=True)\n",
    "# df.collision_date = df.collision_date.str.replace('-','')\n",
    "tuples = [tuple(x) for x in df.to_numpy()]\n",
    "\n",
    "# tupless = pd.read_csv('data/tuples.csv')\n",
    "# tuples = [tuple(x) for x in tupless.to_numpy()]\n",
    "\n",
    "print('Created Tuples')\n",
    "\n",
    "base_url = r\"https://power.larc.nasa.gov/cgi-bin/v1/DataAccess.py?request=execute&identifier=SinglePoint&tempAverage=DAILY&parameters=T2M&startDate={date}&endDate={date}&lat={latitude}&lon={longitude}&outputList={output}&user=DOCUMENTATION\"\n",
    "output = \"JSON\"\n",
    "response = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b31bab93b774ee99aaa4fe740287f6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31858 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ConnectionError",
     "evalue": "None: Max retries exceeded with url: /cgi-bin/v1/DataAccess.py?request=execute&identifier=SinglePoint&tempAverage=DAILY&parameters=T2M&startDate=20170204&endDate=20170204&lat=38.5&lon=-121.5&outputList=JSON&user=CFK0e7I4o9tX0PHPVoyPBfkyUNjSNuogV0frLnKl (Caused by None)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.7/site-packages/urllib3/connection.py\", line 170, in _new_conn\n    (self._dns_host, self.port), self.timeout, **extra_kw\n  File \"/usr/local/lib/python3.7/site-packages/urllib3/util/connection.py\", line 96, in create_connection\n    raise err\n  File \"/usr/local/lib/python3.7/site-packages/urllib3/util/connection.py\", line 86, in create_connection\n    sock.connect(sa)\nTimeoutError: [Errno 60] Operation timed out\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.7/site-packages/urllib3/connectionpool.py\", line 706, in urlopen\n    chunked=chunked,\n  File \"/usr/local/lib/python3.7/site-packages/urllib3/connectionpool.py\", line 382, in _make_request\n    self._validate_conn(conn)\n  File \"/usr/local/lib/python3.7/site-packages/urllib3/connectionpool.py\", line 1010, in _validate_conn\n    conn.connect()\n  File \"/usr/local/lib/python3.7/site-packages/urllib3/connection.py\", line 353, in connect\n    conn = self._new_conn()\n  File \"/usr/local/lib/python3.7/site-packages/urllib3/connection.py\", line 182, in _new_conn\n    self, \"Failed to establish a new connection: %s\" % e\nurllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x1097f7710>: Failed to establish a new connection: [Errno 60] Operation timed out\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.7/site-packages/requests/adapters.py\", line 449, in send\n    timeout=timeout\n  File \"/usr/local/lib/python3.7/site-packages/urllib3/connectionpool.py\", line 756, in urlopen\n    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]\n  File \"/usr/local/lib/python3.7/site-packages/urllib3/util/retry.py\", line 573, in increment\n    raise MaxRetryError(_pool, url, error or ResponseError(cause))\nurllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='power.larc.nasa.gov', port=443): Max retries exceeded with url: /cgi-bin/v1/DataAccess.py?request=execute&identifier=SinglePoint&tempAverage=DAILY&parameters=T2M&startDate=20170204&endDate=20170204&lat=38.5&lon=-121.5&outputList=JSON&user=CFK0e7I4o9tX0PHPVoyPBfkyUNjSNuogV0frLnKl (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x1097f7710>: Failed to establish a new connection: [Errno 60] Operation timed out'))\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n    result = (True, func(*args, **kwds))\n  File \"/Users/dantesean/Documents/Projects/ae-2/Week 3/Assignment/Crashes/worker.py\", line 9, in mp_worker\n    json_response = json.loads(requests.get(api_request_url).content.decode('utf-8'))\n  File \"/usr/local/lib/python3.7/site-packages/requests/api.py\", line 76, in get\n    return request('get', url, params=params, **kwargs)\n  File \"/usr/local/lib/python3.7/site-packages/requests/api.py\", line 61, in request\n    return session.request(method=method, url=url, **kwargs)\n  File \"/usr/local/lib/python3.7/site-packages/requests/sessions.py\", line 542, in request\n    resp = self.send(prep, **send_kwargs)\n  File \"/usr/local/lib/python3.7/site-packages/requests/sessions.py\", line 655, in send\n    r = adapter.send(request, **kwargs)\n  File \"/usr/local/lib/python3.7/site-packages/requests/adapters.py\", line 516, in send\n    raise ConnectionError(e, request=request)\nrequests.exceptions.ConnectionError: HTTPSConnectionPool(host='power.larc.nasa.gov', port=443): Max retries exceeded with url: /cgi-bin/v1/DataAccess.py?request=execute&identifier=SinglePoint&tempAverage=DAILY&parameters=T2M&startDate=20170204&endDate=20170204&lat=38.5&lon=-121.5&outputList=JSON&user=CFK0e7I4o9tX0PHPVoyPBfkyUNjSNuogV0frLnKl (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x1097f7710>: Failed to establish a new connection: [Errno 60] Operation timed out'))\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-3bda8598a017>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mresult_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmp_worker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1681\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1681\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1166\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1167\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1168\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1169\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    746\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 748\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    749\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m     \u001b[0m__next__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m                    \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionError\u001b[0m: None: Max retries exceeded with url: /cgi-bin/v1/DataAccess.py?request=execute&identifier=SinglePoint&tempAverage=DAILY&parameters=T2M&startDate=20170204&endDate=20170204&lat=38.5&lon=-121.5&outputList=JSON&user=CFK0e7I4o9tX0PHPVoyPBfkyUNjSNuogV0frLnKl (Caused by None)"
     ]
    }
   ],
   "source": [
    "## The below block is for Multiprocessing, which turned out not to work due to the limited number of allowed requests\n",
    "# import worker\n",
    "# if __name__ == '__main__':\n",
    "#     try:\n",
    "#         multiprocessing.set_start_method('spawn')\n",
    "#     except RuntimeError:\n",
    "#         pass\n",
    "#     with Pool(10) as p:\n",
    "#         result_list = list(tqdm(p.imap(worker.mp_worker, tuples[1681:]),total=len(tuples[1681:])))\n",
    "#     p.close()\n",
    "#     p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So therefore we turn to the regional data as offered by NASA and specified in their API documentation\n",
    "# This essentially creates a CSV file for every 4.5 x 4.5 block of long/lat combinations, thus in our case creating\n",
    "# 3 x 3 = 9 seperate files. These files are merged in another Notebook.\n",
    "\n",
    "# First, create the 4.5 x 4.5 blocks we want to use\n",
    "longi = [(df.longitude.min(), df.longitude.min() + 4.5), (df.longitude.min() + 4.5, df.longitude.min() + 4.5*2), (df.longitude.min() + 4.5*2, df.longitude.min() + 4.5*3)]\n",
    "lati = [(df.latitude.min(), df.latitude.min() + 4.5), (df.latitude.min() + 4.5, df.latitude.min() + 4.5*2), (df.latitude.min() + 4.5*2, df.latitude.min() + 4.5*3)]\n",
    "\n",
    "# Then, request the data and write to CSV\n",
    "output_folder = r''\n",
    "output = \"CSV\" # JSON, CSV, ASCII, ICASA, NETCDF\n",
    "base_url = r\"https://power.larc.nasa.gov/cgi-bin/v1/DataAccess.py?&request=execute&tempAverage=DAILY&identifier=Regional&parameters=T2M&userCommunity=AG&startDate=20170101&endDate=20171231&bbox={lat0},{long0},{lat1},{long1}&outputList=CSV&user=DOCUMENTATION\"\n",
    "for long in longi:\n",
    "    for lat in lati:\n",
    "        api_request_url = base_url.format(long0=long[0], long1=long[1], lat0=lat[0], lat1=lat[1], output=output.upper())\n",
    "\n",
    "        # Python Memory Object\n",
    "        json_response = json.loads(requests.get(api_request_url).content.decode('utf-8'))\n",
    "\n",
    "        # Selects the file URL from the JSON response\n",
    "        csv_request_url = json_response['outputs'][output.lower()]\n",
    "\n",
    "        # Download File to Folder\n",
    "        output_file_location = os.path.join(output_folder, os.path.basename(csv_request_url))\n",
    "        urllib.request.urlretrieve(csv_request_url, output_file_location)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
