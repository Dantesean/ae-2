{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import tqdm\n",
    "import sqlite3\n",
    "\n",
    "# Read sqlite query results into a pandas DataFrame\n",
    "con = sqlite3.connect(\"data/switrs.sqlite\")\n",
    "q = \"\"\"\n",
    "SELECT collision_date, longitude, latitude FROM collisions\n",
    "WHERE collision_date IS NOT NULL\n",
    "AND longitude IS NOT NULL\n",
    "AND latitude IS NOT NULL    \n",
    "AND collision_date <= '2017-12-31'  -- 2018 is incomplete\n",
    "AND collision_date >= '2017-01-01'\n",
    "\"\"\"\n",
    "df = pd.read_sql_query(q, con)\n",
    "\n",
    "# Round the coordinates, given that NASA only looks at grids of 0.5 x 0.5\n",
    "df.latitude = round(df.latitude*2)/2\n",
    "df.longitude = round(df.longitude*2)/2\n",
    "df.orig = df.copy()\n",
    "\n",
    "# Initially dropped duplicates because that speeds up our investigation\n",
    "df.drop_duplicates(inplace=True)\n",
    "df.columns = ['collision_date', 'LON', 'LAT']\n",
    "\n",
    "# Load in the data retrieved from NASA (which are seperate CSV files made up of 4.5 x 4.5 degree Region data)\n",
    "# See seperate Notebook for loading NASA data\n",
    "path = 'data' # use your path\n",
    "all_files = glob.glob(path + \"/POWER*.csv\")\n",
    "\n",
    "li = []\n",
    "\n",
    "for filename in all_files:\n",
    "    df_ap = pd.read_csv(filename, index_col=None, header=10)\n",
    "    li.append(df_ap)\n",
    "\n",
    "frame = pd.concat(li, axis=0, ignore_index=True)\n",
    "frame['DATE'] = pd.to_datetime(frame['DOY'], format='%j').dt.strftime('2017-%m-%d')\n",
    "frame.drop(['YEAR', 'DOY'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create functions for finding the closest point to a point and matching another field to it\n",
    "from scipy.spatial.distance import cdist\n",
    "def closest_point(point, points):\n",
    "    \"\"\" Find closest point from a list of points. \"\"\"\n",
    "    return points[cdist([point], points).argmin()]\n",
    "\n",
    "def match_value(df, col1, x, col2, y, col3):\n",
    "    \"\"\" Match value x from col1 row to value in col2. \"\"\"\n",
    "    return df[(df[col1] == x) & (df[col3] == y)][col2].values[0]\n",
    "\n",
    "\n",
    "df1 = frame\n",
    "df2 = df.copy()\n",
    "\n",
    "import time\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "df1['point'] = [(x, y) for x,y in zip(df1['LAT'], df1['LON'])]\n",
    "df2['point'] = [(x, y) for x,y in zip(df2['LAT'], df2['LON'])]\n",
    "\n",
    "df2['closest'] = [closest_point(x, list(df1['point'])) for x in tqdm.tqdm(df2['point'])]\n",
    "df2['T2M'] = [match_value(df1, 'point', x, 'T2M', y, 'DATE') for x,y in tqdm.tqdm(zip(df2['closest'], df2['collision_date']))]\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "total = t1-t0\n",
    "print('Finished in ')\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write this file to a CSV for intermediate checkpoint saving\n",
    "df2.to_csv('data/supermegafinal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, initialize the original data frame\n",
    "df_orig.columns = ['collision_date', 'LON', 'LAT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the points (this time a three element tuple) for the original date sets\n",
    "df_orig['point'] = [(x,y,z) for x,y,z in zip(df_orig['LAT'], df_orig['LON'], df_orig['collision_date'])]\n",
    "df2['point_date'] = [(x,y,z) for x,y,z in zip(df2['LAT'], df2['LON'], df2['collision_date'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 292296/292296 [15:25<00:00, 315.79it/s]\n"
     ]
    }
   ],
   "source": [
    "# Match the original dataset to the already matched data of the unique values, done earlier\n",
    "def match_value_2(df, col1, x, col2):\n",
    "    \"\"\" Match value x from col1 row to value in col2. \"\"\"\n",
    "    return df[(df[col1] == x)][col2].values[0]\n",
    "\n",
    "df_orig['T2M'] = [match_value_2(df2, 'point_date', x, 'T2M') for x in tqdm.tqdm(df_orig['point'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the final file to CSV\n",
    "df_orig.to_csv('data/collisionweather.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orig['T2M'].value_counts().to_csv('data/collisionweather_valuecounts.csv', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2017-11-17    1189\n",
       "2017-10-27    1141\n",
       "2017-11-16    1140\n",
       "2017-10-20    1109\n",
       "2017-11-09    1082\n",
       "              ... \n",
       "2017-02-05     521\n",
       "2017-01-02     506\n",
       "2017-01-15     478\n",
       "2017-12-31     468\n",
       "2017-12-25     426\n",
       "Name: collision_date, Length: 365, dtype: int64"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_orig.collision_date.value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
