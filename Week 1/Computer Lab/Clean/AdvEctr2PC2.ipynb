{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Econometrics 2 (2020/2021) - Bootstrap Methods\n",
    "\n",
    "Computer Class 1b (Wednesday)\n",
    "\n",
    "*Aim of this computer class*: to gain practical experience of bootstrapping regression models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11-1\n",
    "\n",
    "Consider the model $y=\\alpha+\\beta x+\\varepsilon$, where $\\alpha$, $\\beta$, and $x$ are scalars and $\\varepsilon \\sim N(0,\\sigma^2)$. A sample of size $N=20$ is generated with $\\alpha=2, \\beta=1, \\sigma^2=1$ and $x \\sim N(2,2)$. We wish to test $H_0: \\beta=1$ against $H_1: \\beta\\neq 1$  at level 0.05 using the t-statistic $t=(\\hat{\\beta}-1)/SE[\\hat{\\beta}]$. Use $B = 999$ bootstrap replications. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OLS(y,X):\n",
    "    N,k = X.shape                   # number of observations and regressors\n",
    "    XXi = np.linalg.inv(X.T @ X)\n",
    "    b_ols = XXi @ (X.T @ y)\n",
    "    res = y-X @ b_ols\n",
    "    s2 = (res @ res)/(N-k)\n",
    "    SE = np.sqrt(s2*np.diag(XXi))\n",
    "    return b_ols,SE,res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **(a)** Estimate the model by OLS, giving slope estimate $\\hat{\\beta}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "y  =np.array([2.463460087, 4.082339785,7.14245305 ,6.837688781, 3.188993095,4.838084255,5.354217263,5.024464493,4.278112328, 2.061616983,-0.655026946,6.637085435, 1.822475278, 3.440341802,6.294259862, 4.225766242,4.901194854, 2.293813513,3.278865984,5.515655038])\n",
    "x  =np.array([0.259705633, 2.481299324,3.960540791,3.49720621,  2.133512947,1.530091473,3.265568683,3.797276605,1.184917425, 0.462349978,-2.149324397,4.470384733, 1.343208036, 1.693754991,3.869958201, 2.789750994,2.867776386, 0.393884163,1.918828592,2.983220267])\n",
    "eps=np.array([0.203754454,-0.39895954, 1.181912259,1.340482571,-0.944519852,1.307992781,0.08864858,-0.772812112,1.093194903,-0.400732995,-0.505702548,0.166700702,-1.520732758,-0.253413189,0.424301661,-0.563984752,0.033418467,-0.10007065,-0.639962608,0.532434771])\n",
    "N=len(y)\n",
    "alpha=2\n",
    "beta=1\n",
    "const=np.ones(N)\n",
    "X=np.vstack( (const,x) ).T\n",
    "# continue below\n",
    "b_ols, b_ols_se, res = OLS(y,X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **(b)** Use a paired bootstrap to compute the standard error and compare this to the original sample estimate. Use the bootstrap standard error to test $H_0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results paired boostrap (B=9999):\n",
      "  Bootstrapped SE:        0.0956\n",
      "  t-stat using SE.boot:   1.3030\n"
     ]
    }
   ],
   "source": [
    "w=np.vstack( (y,x) ).T                 # make pairs\n",
    "BOOTREP=9999;                          # number of bootstrap replications\n",
    "betaB=np.zeros(BOOTREP)                # initialise to zero\n",
    "tB=np.zeros(BOOTREP)\n",
    "np.random.seed(42)\n",
    "for b in range(BOOTREP):\n",
    "    index=np.random.randint(N,size=N)  # select the indices  \n",
    "                                       # resample from data\n",
    "\n",
    "    yB = y[index]                                   # obtain bootstrap estimates using OLS(.)-function    \n",
    "    XB = np.vstack((const, x[index])).T\n",
    "    bB_ols, bB_ols_se, res_b = OLS(yB,XB)\n",
    "    betaB[b] = bB_ols[1]\n",
    "    tB[b]=(betaB[b]-b_ols[1])/bB_ols_se[1]                           # store bootstrapped t-statistic\n",
    "print('Results paired boostrap (B=%d):' % BOOTREP)\n",
    "print('  Bootstrapped SE:       %7.4f' % np.std(betaB));\n",
    "print('  t-stat using SE.boot:  %7.4f' % ((b_ols[1]-beta)/np.std(betaB)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.83285903, 1.09680483]),\n",
       " array([0.21040615, 0.06614074]),\n",
       " array([-0.06033325,  0.41078563,  0.216812  , -0.1304966 , -0.97326584,\n",
       "        -0.06033325, -0.6585735 , -0.1304966 , -0.1304966 ,  1.16907711,\n",
       "        -0.97326584,  0.96565377, -0.47202031, -0.09891314,  1.32701352,\n",
       "        -0.47202031,  0.34575467, -0.09891314, -0.09891314, -0.07705515]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OLS(yB,XB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **(c)** Use a paired bootstrap based on an asymptotic pivotal test statistic to test $H_0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2.5% bootstrap quantile:   -1.539\n",
      "97.5% bootstrap quantile:    1.526\n"
     ]
    }
   ],
   "source": [
    "print(' 2.5%% bootstrap quantile: %8.3f' % np.quantile(tB,0.025))\n",
    "print('97.5%% bootstrap quantile: %8.3f' % np.quantile(tB,0.975))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d) Use a residual bootstrap to compute the standard error and compare this to the original sample estimate. Use the bootstrap standard error to test $H_0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results residual boostrap (B=9999):\n",
      "  Bootstrapped SE:        0.1063\n",
      "  t-stat using SE.boot:   1.1722\n"
     ]
    }
   ],
   "source": [
    "fit=X@b_ols\n",
    "np.random.seed(42)\n",
    "for b in range(BOOTREP):\n",
    "    index=np.random.randint(N,size=N)  # select the indices  \n",
    "    resB=res[index]                              # resample from residuals\n",
    "    yB=fit + resB                                # construct boostrap observables\n",
    "    bB_ols,SEB,resB=OLS(yB, X)                   # obtain bootstrap estimates using OLS(.)-function    \n",
    "    betaB[b]=bB_ols[1]                          # store bootstrapped regression coefficient\n",
    "    tB[b]=(betaB[b] - b_ols[1])/SEB[1]                             # store bootstrapped t-statistic\n",
    "print('Results residual boostrap (B=%d):' % BOOTREP)\n",
    "print('  Bootstrapped SE:      %8.4f' % np.std(betaB));\n",
    "print('  t-stat using SE.boot: %8.4f' % ((b_ols[1]-beta)/np.std(betaB)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **(e)** Use a residual bootstrap with asymptotic refinement to test $H_0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2.5% bootstrap quantile:   -2.128\n",
      "97.5% bootstrap quantile:    2.050\n"
     ]
    }
   ],
   "source": [
    "print(' 2.5%% bootstrap quantile: %8.3f' % np.quantile(tB,0.025))\n",
    "print('97.5%% bootstrap quantile: %8.3f' % np.quantile(tB,0.975))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11-2\n",
    "\n",
    "A sample of size 20 is generated according to the following DGP. Two regressors are generated by $x_1\\sim \\chi^2(4)-4$ and $x_2 \\sim 3.5+\\mathcal{U}[1,2]$; the error is from a mixture of normals with $u \\sim N(0,25)$ with probability 0.3 and $u \\sim N(0,5)$ with probability 0.7; and the dependent variable is $y=1.3\\cdot x_1+0.7\\cdot x_2+0.5\\cdot u$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **(a)** Estimate by OLS the model $y=\\beta_0+\\beta_1\\cdot x_1+\\beta_2\\cdot x_2+u$. Also obtain the variance-covariance matrix of the OLS estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      C          X1         X2\n",
      "OLS estimates:    -8.7716    1.4738    2.4641\n",
      "Standard errors: ( 7.2042) ( 0.1535) ( 1.4426)\n",
      "Covariance matrix\n",
      "[[ 51.9007  -0.093  -10.3767]\n",
      " [ -0.093    0.0236   0.0197]\n",
      " [-10.3767   0.0197   2.081 ]]\n"
     ]
    }
   ],
   "source": [
    "y =np.array([-1.68394399, 1.89893235  ,5.587108425, 4.040390467,13.20263535 ,12.9103882  ,4.742519161,-0.22837419 , 0.997667496, 3.917611056,5.264028901,5.470083648,-2.736489722,-0.700599201, 2.968735541, 1.731689435,-1.626249678, 0.246495836, 3.040399679,4.966098157])\n",
    "x1=np.array([-2.466038711,-0.039161303,0.746740798, 0.370547493, 5.807525562, 6.442885266,0.296510257,-3.434583623,-2.372860055,-2.95813237 ,0.499211306,1.106643338,-1.587499657,-2.36526624 ,-0.789818973,-0.553989793,-3.098652021,-1.793674939, 1.674597685,0.167786355])\n",
    "x2=np.array([ 5.156698473, 4.709976091,4.963574179, 5.441221931, 5.216287314, 4.576500608,5.148811731, 5.168776938, 4.699506648, 5.411501169,4.847301769,5.211460017, 5.048981452, 4.572994183, 5.334505106, 4.877380298, 4.557628807, 5.14582404 , 4.727755237,4.95463344])\n",
    "u =np.array([-4.175565193,-2.69428244 ,2.283686924,-0.50035325 , 4.002901992, 2.662173856,1.50577523 , 1.236881328, 1.585461827, 7.950264637,2.44388593 ,0.766850592,-8.41405437,-1.653698034 , 0.522693263,-1.924580086,-1.576684432,-2.047607142,-4.892011955,2.559464974])\n",
    "N=len(y)\n",
    "beta0=0\n",
    "beta1=1.3\n",
    "beta2=0.5\n",
    "const=np.ones(N)\n",
    "X=np.vstack( (const,x1,x2) ).T\n",
    "k=np.shape(X)[1]\n",
    "# continue below\n",
    "b_ols,SE,res = OLS(y,X)\n",
    "print('                      C          X1         X2')\n",
    "print('OLS estimates:    %7.4f   %7.4f   %7.4f' % (b_ols[0],b_ols[1],b_ols[2]) )\n",
    "print('Standard errors: (%7.4f) (%7.4f) (%7.4f)' % (SE[0],SE[1],SE[2]) )\n",
    "s2 = (res @ res)/(N-k)\n",
    "V = s2*np.linalg.inv(X.T@X)\n",
    "print('Covariance matrix')\n",
    "with np.printoptions(precision=4, suppress=True):\n",
    "    print(V)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **(b)** Suppose we are interested in estimating the quantity $\\gamma=\\beta_1+\\beta_2^2$  from the data. Use the least-squares estimates to estimate this quantity. Use the delta method to obtain approximate standard error for this function.\n",
    "\n",
    "- Delta method: let $\\theta=\\left (\\begin{array}{c}\\beta_1 \\\\ \\beta_2 \\end{array} \\right)$, so that $\\gamma=h(\\theta)=\\beta_1+\\beta_2^2$.\n",
    "- Then we have $R(\\theta)=\\frac{\\partial h(θ)}{\\partial θ'}=(1,2β_2)$, so that $V(\\hat{\\gamma})\\approx R(\\hat{\\theta})V(\\hat{\\theta})R'(\\hat{\\theta})$ (see p. 231 of the book;  § 7.2.8).\n",
    "- This means that $V(\\hat{\\theta})≈V(\\hat{\\beta}_1)+4\\hat{\\beta}_2^2 V(\\hat{\\beta}_2)+4\\hat{\\beta}_2 Cov(\\hat{\\beta}_1,\\hat{\\beta}_2).$\n",
    "\n",
    "Determine the point estimate and its standard error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma_hat (SE):  7.5456 ( 7.1245)\n",
      "t-stat:  0.9187\n"
     ]
    }
   ],
   "source": [
    "gamma_hat=b_ols[1] + b_ols[2]**2\n",
    "R=np.array([0,1,2*b_ols[2]])\n",
    "se_gamma=np.sqrt(R@V@R.T)\n",
    "tstat=(gamma_hat-1)/se_gamma\n",
    "print('gamma_hat (SE): %7.4f (%7.4f)' % (gamma_hat,se_gamma) )\n",
    "print('t-stat: %7.4f' % tstat);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **(c)** Then estimate the standard error of $\\hat{\\gamma}$ using a paired bootstrap. Compare this to $SE[\\hat{\\gamma}]$ from part (b) and explain the difference. For the bootstrap use $B=25$ and $B=200$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results paired boostrap (B=25):\n",
      "  Bootstrapped SE:   4.6326\n",
      "  t-stat (SE.boot):  1.4130\n",
      "\n",
      "Results paired boostrap (B=200):\n",
      "  Bootstrapped SE:   6.6318\n",
      "  t-stat (SE.boot):  0.9870\n",
      "\n",
      "Results paired boostrap (B=1000):\n",
      "  Bootstrapped SE:   7.9764\n",
      "  t-stat (SE.boot):  0.8206\n",
      "\n"
     ]
    }
   ],
   "source": [
    "w=np.vstack( (y,x1,x2) ).T                # make pairs\n",
    "for BOOTREP in (25,200,1000):\n",
    "    gammaB_hat=np.zeros(BOOTREP)              # initialise to zero\n",
    "    se_gammaB=np.zeros(BOOTREP)\n",
    "    tB=np.zeros(BOOTREP)\n",
    "    np.random.seed(3)\n",
    "    for b in range(BOOTREP):\n",
    "        index=np.random.randint(N,size=N)  # select the indices  \n",
    "        wB=np.copy(w[index,])              # resample from data\n",
    "        yB=wB[:,0]\n",
    "        XB=np.vstack( (const,wB[:,1],wB[:,2]) ).T\n",
    "        bB_ols,SEB,resB=OLS(yB,XB)         # obtain bootstrap estimates using OLS(.)-function    \n",
    "        gammaB_hat[b]=bB_ols[1] + bB_ols[2]**2\n",
    "        RB=np.array([0,1,2*bB_ols[2]])        \n",
    "        se_gammaB[b]=np.sqrt(R@V@R.T)\n",
    "        tB[b]=(gammaB_hat[b]-gamma_hat)/se_gammaB[b]\n",
    "    print('Results paired boostrap (B=%d):' % BOOTREP)\n",
    "    print('  Bootstrapped SE:  %7.4f' % np.std(gammaB_hat,ddof=1))\n",
    "    print('  t-stat (SE.boot): %7.4f\\n' % ((gamma_hat-1)/np.std(gammaB_hat,ddof=1)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **(d)** Now test $H_0:\\gamma=1$ at level 0.05 using a paired bootstrap with $B=999$. Perform bootstrap tests without asymptotic refinement, i.e. using $SE_{Boot}[\\hat{\\gamma}]$ of (c),  and with asymptotic refinement, i.e. using $T^*=(\\hat{\\gamma}^*-\\hat{\\gamma})/SE(\\hat{\\gamma}^*)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2.5% quantile:   -0.826\n",
      "97.5% quantile:    2.947\n"
     ]
    }
   ],
   "source": [
    "print(' 2.5%% quantile: %8.3f' % np.quantile(tB,0.025))\n",
    "print('97.5%% quantile: %8.3f' % np.quantile(tB,0.975))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
